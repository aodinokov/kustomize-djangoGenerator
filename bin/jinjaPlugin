#!/usr/bin/python3

import logging
import os
import base64
import sys
import copy
import yaml
from collections import OrderedDict
from jinja2 import Environment
from functools import reduce
import operator

# yaml-helpers: to avoid reordering of fields when read yaml, we need to use OrderedDict
# see
# https://github.com/yaml/pyyaml/issues/110 and
# https://stackoverflow.com/questions/5121931/in-python-how-can-you-load-yaml-mappings-as-ordereddicts
def _yaml_orderedLoad(arg, _all=False, Loader=yaml.Loader, object_pairs_hook=OrderedDict):
    class OrderedLoader(Loader):
        pass
    def construct_mapping(loader, node):
        loader.flatten_mapping(node)
        return object_pairs_hook(loader.construct_pairs(node))
    OrderedLoader.add_constructor(
        yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG,
        construct_mapping)
    if _all == True:
        return yaml.load_all(arg, OrderedLoader)
    return yaml.load(arg, OrderedLoader)

def _yaml_orderedDump(data, _all=False, stream=None, Dumper=yaml.Dumper, **kwds):
    class OrderedDumper(Dumper):
        pass
    def _dict_representer(dumper, data):
        return dumper.represent_mapping(
            yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG,
            data.items())
    OrderedDumper.add_representer(OrderedDict, _dict_representer)
    if _all == True:
        result = ''
        for y in data:
            result+=yaml.dump(y, stream, OrderedDumper, **kwds)
            result+='---\n'
        return result
    return yaml.dump(data, stream, OrderedDumper, **kwds)

def yaml_load(y, _all=False):
    return _yaml_orderedLoad(y, _all=_all)

def yaml_dump(y, _all=False):
    return _yaml_orderedDump(y, default_flow_style=False, _all=_all)

def yaml_dumpAll(y):
    return yaml_dump(y, _all=True)

# symmetric-encryption-helper: the basic functionality to decrypt/encrypt configential data
# see https://nitratine.net/blog/post/encryption-and-decryption-in-python/#what-is-symmetric-encryption
def _crypt_getKeyFromPassword(password_provided):
    from cryptography.hazmat.backends import default_backend
    from cryptography.hazmat.primitives import hashes
    from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC

    password = password_provided.encode() # Convert to type bytes
    salt = b'salt_' # CHANGE THIS - recommend using a key from os.urandom(16), must be of type bytes
    kdf = PBKDF2HMAC(
        algorithm=hashes.SHA256(),
        length=32,
        salt=salt,
        iterations=100000,
        backend=default_backend()
    )
    return base64.urlsafe_b64encode(kdf.derive(password))

def _crypt_getKey():
    return _crypt_getKeyFromPassword(os.environ['JINJA_CRYPT_PASSWORD'])

def crypt_encrypt(s):
    from cryptography.fernet import Fernet
    f = Fernet(_crypt_getKey())
    return base64.b64encode(f.encrypt(s.encode())).decode()

def crypt_decrypt(e):
    from cryptography.fernet import Fernet
    f = Fernet(_crypt_getKey())
    return f.decrypt(base64.b64decode(e.encode())).decode()

# vault-helper:
# see more https://www.vaultproject.io/docs/commands/
# https://github.com/hvac/hvac 
# and https://hvac.readthedocs.io/en/stable/overview.html#getting-started
def vault_getClient():
    import hvac
    # TODO: read some extended params from file if needed (in home dir or provided via env)
    return hvac.Client(url = os.environ['VAULT_ADDR'],
            token=os.environ['VAULT_TOKEN'])

# taken from https://stackoverflow.com/questions/14692690/access-nested-dictionary-items-via-a-list-of-keys
# can also use https://pypi.org/project/dpath/ 
def _dict_getByPath(dataDict, path):
    mapList = [int(i) if i.isdigit() else i for i in path.split('/')]
    try:
        return reduce(operator.getitem, mapList, dataDict)
    except:
        #TODO: catch only corrent exceptions
        logger.error("filter_fieldExits error: {}\n".format(str(sys.exc_info()[0])))
    return None

def dict_getByPath(dataDict, pathComplex, _all=False):
    val = dataDict
    pathList = pathComplex.split('|')
    for i in range(len(pathList)):
        res = _dict_getByPath(val, pathList[i])
        if i == (len(pathList) - 1):
            return res
        val = yaml_load(res, _all=_all)   # _all allows to parse yaml with many yamls as string in the field

def dict_setByPath(dataDict, pathComplex, value, _all=False):
    res = value
    pathList = pathComplex.split('|')
    if (len(pathList) > 0):
        mapList = [int(i) if i.isdigit() else i for i in pathList[0].split('/')]
        res = copy.deepcopy(dataDict)
        if len(pathList) == 1:
            reduce(operator.getitem, mapList[:-1], res)[mapList[-1]] = value
        else:
            org = reduce(operator.getitem, mapList[:-1], dataDict)[mapList[-1]]
            reduce(operator.getitem, mapList[:-1], res)[mapList[-1]] = \
                    yaml_dump(dict_setByPath(yaml_load(org, _all=_all), pathList[1:].join('|'), value), _all=_all)
    return res

def dict_update(dataDict1, dataDict2):
    dataDict1_copy = copy.deepcopy(dataDict1)
    dataDict1_copy.update(dataDict2)
    return dataDict1_copy

def filter_fieldExist(path):
    def _exist(dataDict):
        logger.debug("closure path={}\n".format(str(path)))
        return not _dict_getByPath(dataDict, path) is None
    return logger_wrap(_exist)
        
def filter_fieldEqual(path, val):
    def _equal(dataDict):
        logger.debug("closure path={} val={}\n".format(str(path),str(val)))
        if _dict_getByPath(dataDict, path) == val:
            result = True
        return False
    return logger_wrap(_equal)

def filter_operatorNot(filterToInvert):
    def _not(dataDict):
        return not filterToInvert(dataDict)
    return logger_wrap(_not)

def filter_operatorAnd(*args):
    if len(args) < 2:
        raise ValueError('filter_operatorAnd needs at least 2 arguments')
    def _and(dataDict):
        for i in args:
            if not i(dataDict):
                return False
        return True
    return logger_wrap(_and)

def filter_operatorOr(*args):
    if len(args) < 2:
        raise ValueError('filter_operatorOr needs at least 2 arguments')
    def _or(dataDict):
        for i in args:
            if i(dataDict):
                return True
        return False
    return logger_wrap(_or)

def filter_getMatchingIndexes(dataDictArray, filterToApply):
    result = []
    for i in range(len(dataDictArray)):
        if filterToApply(dataDictArray[i]):
            result.append(i)
    return result

def logger_wrap(fn):
    def wrapper(*args, **kwargs):
        logger.debug("{} args=\n\t{}\n\tkwargs={}\n".format(fn.__name__, str(args), str(kwargs)))
        result = fn(*args, *kwargs)
        logger.debug("{} result=\n\t{}\n".format(fn.__name__, str(result)))
        return result
    return wrapper

def get_functions():
    return {
        'yaml_load': logger_wrap(yaml_load),
        'yaml_dump': logger_wrap(yaml_dump),
        'yaml_dumpAll': logger_wrap(yaml_dumpAll),
        'crypt_encrypt': logger_wrap(crypt_encrypt),
        'crypt_decrypt': logger_wrap(crypt_decrypt),
        'vault_getClient': logger_wrap(vault_getClient),
        'dict_getByPath': logger_wrap(dict_getByPath),
        'dict_setByPath': logger_wrap(dict_setByPath), 
        'dict_update': logger_wrap(dict_update), 
        'filter_fieldExist': logger_wrap(filter_fieldExist),
        'filter_fieldEqual': logger_wrap(filter_fieldEqual),
        'filter_operatorNot': logger_wrap(filter_operatorNot),
        'filter_operatorAnd': logger_wrap(filter_operatorAnd),
        'filter_operatorOr': logger_wrap(filter_operatorOr),
        'filter_getMatchingIndexes': logger_wrap(filter_getMatchingIndexes), }
#-------------------------------------------------------------------
def get_input():
    input = []
    for i in yaml_load(sys.stdin, _all=True):
        input.append(i)
    return input

def render_JinjaCatalog(global_obj):

    apiVersion = global_obj["config"].get("apiVersion")
    kind = global_obj["config"].get("kind")
    data = global_obj["config"].get("data")
    parents = global_obj["config"].get("parents")
    jinjaTemplate = global_obj["config"].get("jinjaTemplate")

    if apiVersion is None or kind is None or kind != "JinjaCatalog":
        logger.debug("returning non JinjaCatalog yaml:\n{}\n".format(str(global_obj["config"])))
        return global_obj["config"]

    if jinjaTemplate is None:
        sys.exit("wasn't able to find jinjaTemplate - exiting")

    if not data is None:
        global_obj["data"] = data

    if not parents is None:
        for parent in parents:

            parent_root = parent.get('root')
            parent_jinjaCatalog = parent.get('jinjaCatalog')
            if parent_root is None:
                sys.exit("parent must contain root - exiting")

            if parent_jinjaCatalog is None:
                parent_jinjaCatalog = 'jinjacatalog.yaml'

            parent_obj = yaml_load(get_renderred_JinjaCatalog(os.path.realpath(os.path.join(global_obj['config_root'], parent_root)), parent_jinjaCatalog))
            if parent_obj is None:
                sys.exit("couldn't read yaml - for parent {} exiting".format(str(parent)))

            parent["obj"] = parent_obj

    logger.debug("rendering with global_obj={}\n".format(str(global_obj)))

    env = Environment()
    template = env.from_string(jinjaTemplate)
    rendered = template.render(global_obj)

    logger.debug("rendered ={}\n".format(str(rendered)))

    return rendered

def get_renderred_JinjaCatalog(config_root, config_jinjaCatalog):

    global_obj = {
        'functions': get_functions(),
        'config_root': config_root}

    with open(os.path.join(config_root, config_jinjaCatalog)) as f:
        global_obj["config"] = yaml_load(f)
    if  global_obj["config"] is None:
        sys.exit("wasn't able to read {}".format(str(config_jinjaCatalog)))

    return render_JinjaCatalog(global_obj)

def render_JinjaGenerator(global_obj):
    config_jinjaCatalog = global_obj["config"].get("jinjaCatalog")
    if config_jinjaCatalog is None:
        sys.exit("mandatory field jinjaCatalog is missed")

    config_jinjaTemplate = global_obj["config"].get("jinjaTemplate")
    if config_jinjaTemplate is None:
        sys.exit("mandatory field jinjaTemplate is missed")

    jinjaCatalog_yaml = yaml_load(get_renderred_JinjaCatalog(global_obj['config_root'], config_jinjaCatalog))
    if jinjaCatalog_yaml is None:
        sys.exit("couldn't ready yaml")

    jinjaCatalog_yaml_kind = jinjaCatalog_yaml.get("kind")

    if jinjaCatalog_yaml_kind is None or jinjaCatalog_yaml_kind != "JinjaCatalog":
        sys.exit("resource transformed not to JinjaCatalog kind")

    global_obj["catalog"] = jinjaCatalog_yaml

    logger.debug("rendering with global_obj={}\n".format(str(global_obj)))

    env = Environment()
    template = env.from_string(config_jinjaTemplate)
    rendered =  template.render(global_obj)

    logger.debug("rendered ={}\n".format(str(rendered)))

    return rendered

def render_JinjaTransformer(global_obj):
    global_obj["resources"] = get_input()

    return render_JinjaGenerator(global_obj)

# the main configuration processing function
def process_config(config_root, config_string):
    logger.debug("process_config config_root={}, config_string:\n{}\n".format(str(config_root), str(config_string)))

    global_obj = {
        'functions': get_functions(), 
        'config_root': config_root}

    global_obj["config"] = yaml_load(config_string)
    if global_obj["config"] is None:
        sys.exit("wasn't able to read config")
    logger.debug("config:\n{}\n".format(str(global_obj["config"])))

    config_kind = global_obj["config"].get("kind")
    if config_kind is None:
        sys.exit("config doesn't have kind field - exiting")
    logger.debug("config.kind = {}\n".format(str(config_kind)))

    if config_kind == 'JinjaGenerator':
        print(render_JinjaGenerator(global_obj))
    elif config_kind == "JinjaTransformer":
        print(render_JinjaTransformer(global_obj))
    elif config_kind == 'JinjaCatalog':
        print(render_JinjaCatalog(global_obj))

# configure logger
logger = logging.getLogger('jinjaPlugin')
logger.setLevel(logging.DEBUG)
ch = logging.StreamHandler()
if not os.environ.get('JINJA_DEBUG') is None and int(os.environ['JINJA_DEBUG']) > 0:
    ch.setLevel(logging.DEBUG)
else:
    ch.setLevel(logging.ERROR)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
ch.setFormatter(formatter)
logger.addHandler(ch)

# do the actual work
process_config(
    os.environ['KUSTOMIZE_PLUGIN_CONFIG_ROOT'],
    os.environ['KUSTOMIZE_PLUGIN_CONFIG_STRING'])

